#!/usr/bin/env python3
"""
Query Executor - Execute SQL queries generated by sql_generator_from_graphs.py
"""
import sys
import os
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from pathlib import Path
import sqlite3
import json
import time
from sql_generator_from_graphs import generate_queries_for_database, SQLFromGraphGenerator

class QueryExecutor:
    """Execute SQL queries against databases and report results."""
    
    def __init__(self):
        self.db_dir = Path('../bird/train/train_databases/train_databases')
        self.results = []
        
    def execute_query(self, query_data, db_path):
        """Execute a single query and return results."""
        try:
            start_time = time.time()
            
            # Connect to database
            conn = sqlite3.connect(str(db_path))
            cursor = conn.cursor()
            
            # Execute query
            cursor.execute(query_data['sql'])
            results = cursor.fetchall()
            
            execution_time = time.time() - start_time
            conn.close()
            
            return {
                'success': True,
                'result_count': len(results),
                'execution_time': execution_time,
                'error': None,
                'first_few_results': results[:3] if results else []  # First 3 rows for preview
            }
            
        except Exception as e:
            return {
                'success': False,
                'result_count': 0,
                'execution_time': time.time() - start_time if 'start_time' in locals() else 0,
                'error': str(e),
                'first_few_results': []
            }
    
    def execute_queries_for_database(self, db_name, num_queries=5):
        """Generate and execute queries for a specific database."""
        print(f"🔧 Executing queries for database: {db_name}")
        
        # Find database file
        db_path = self.db_dir / db_name / f"{db_name}.sqlite"
        if not db_path.exists():
            print(f"❌ Database file not found: {db_path}")
            return []
        
        # Generate queries
        queries = generate_queries_for_database(db_name, num_queries)
        if not queries:
            print(f"❌ No queries generated for {db_name}")
            return []
        
        print(f"📝 Generated {len(queries)} queries, executing...")
        
        # Execute each query
        execution_results = []
        successful_queries = 0
        
        for i, query in enumerate(queries, 1):
            print(f"   🔄 Executing query {i}/{len(queries)}...")
            
            # Execute query
            exec_result = self.execute_query(query, db_path)
            
            # Combine query data with execution results
            full_result = {
                'query_id': i,
                'database': db_name,
                'sql': query['sql'],
                'path': query['path'],
                'path_length': query['path_length'],
                'join_type': query['join_type'],
                **exec_result
            }
            
            execution_results.append(full_result)
            
            if exec_result['success']:
                successful_queries += 1
                print(f"      ✅ Success: {exec_result['result_count']} rows in {exec_result['execution_time']:.3f}s")
            else:
                print(f"      ❌ Error: {exec_result['error'][:60]}...")
        
        success_rate = (successful_queries / len(queries)) * 100
        print(f"   📊 Success rate: {successful_queries}/{len(queries)} ({success_rate:.1f}%)")
        
        return execution_results
    
    def execute_batch_test(self, num_databases=5, queries_per_db=5):
        """Execute queries on multiple random databases."""
        print("🎯 Batch Query Execution Test")
        print("=" * 50)
        
        # Get available databases
        available_dbs = []
        if self.db_dir.exists():
            for db_folder in self.db_dir.iterdir():
                if db_folder.is_dir():
                    sqlite_file = db_folder / f"{db_folder.name}.sqlite"
                    if sqlite_file.exists():
                        available_dbs.append(db_folder.name)
        
        if not available_dbs:
            print("❌ No databases found!")
            return []
        
        print(f"🗄️ Found {len(available_dbs)} databases")
        
        # Select random databases to test
        import random
        test_databases = random.sample(available_dbs, min(num_databases, len(available_dbs)))
        
        all_results = []
        total_queries = 0
        total_successful = 0
        
        for db_name in test_databases:
            print(f"\n🗄️ Testing database: {db_name}")
            
            try:
                results = self.execute_queries_for_database(db_name, queries_per_db)
                all_results.extend(results)
                
                # Count successes
                successful = sum(1 for r in results if r['success'])
                total_queries += len(results)
                total_successful += successful
                
            except Exception as e:
                print(f"   ❌ Database {db_name} failed: {str(e)[:50]}...")
                continue
        
        # Overall summary
        overall_success_rate = (total_successful / total_queries * 100) if total_queries > 0 else 0
        print(f"\n📊 OVERALL SUMMARY:")
        print(f"   Databases tested: {len(test_databases)}")
        print(f"   Total queries: {total_queries}")
        print(f"   Successful queries: {total_successful}")
        print(f"   Overall success rate: {overall_success_rate:.1f}%")
        
        return all_results
    
    def save_results(self, results, filename="query_execution_results.json"):
        """Save execution results to JSON file."""
        output_file = Path(filename)
        
        # Prepare summary data
        summary_data = {
            'execution_timestamp': time.strftime('%Y-%m-%d %H:%M:%S'),
            'total_queries': len(results),
            'successful_queries': sum(1 for r in results if r['success']),
            'databases_tested': len(set(r['database'] for r in results)),
            'results': results
        }
        
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(summary_data, f, indent=2, ensure_ascii=False)
        
        print(f"💾 Results saved to: {output_file}")
        return output_file
    
    def analyze_errors(self, results):
        """Analyze common error patterns."""
        print(f"\n🔍 Error Analysis:")
        
        errors = [r for r in results if not r['success']]
        if not errors:
            print("   ✅ No errors found!")
            return
        
        # Group errors by type
        error_types = {}
        for error_result in errors:
            error_msg = error_result['error']
            # Categorize error
            if 'no such column' in error_msg.lower():
                error_types['column_not_found'] = error_types.get('column_not_found', 0) + 1
            elif 'no such table' in error_msg.lower():
                error_types['table_not_found'] = error_types.get('table_not_found', 0) + 1
            elif 'syntax error' in error_msg.lower():
                error_types['syntax_error'] = error_types.get('syntax_error', 0) + 1
            else:
                error_types['other'] = error_types.get('other', 0) + 1
        
        print(f"   Total errors: {len(errors)}")
        for error_type, count in error_types.items():
            print(f"   - {error_type}: {count}")
        
        # Show a few example errors
        print(f"\n   Example errors:")
        for i, error_result in enumerate(errors[:3], 1):
            print(f"   {i}. DB: {error_result['database']}, Error: {error_result['error'][:80]}...")

def test_specific_database(db_name, num_queries=10):
    """Test a specific database with detailed output."""
    executor = QueryExecutor()
    results = executor.execute_queries_for_database(db_name, num_queries)
    
    if results:
        # Show detailed results
        print(f"\n📋 Detailed Results for {db_name}:")
        for result in results:
            print(f"\nQuery {result['query_id']}:")
            print(f"  Path: {' -> '.join(result['path'])}")
            print(f"  SQL: {result['sql'][:100]}...")
            if result['success']:
                print(f"  ✅ Success: {result['result_count']} rows")
                if result['first_few_results']:
                    print(f"  Sample: {result['first_few_results'][0] if result['first_few_results'] else 'No data'}")
            else:
                print(f"  ❌ Error: {result['error']}")
        
        executor.save_results(results, f"{db_name}_execution_results.json")
        executor.analyze_errors(results)

if __name__ == "__main__":
    if len(sys.argv) > 1:
        # Test specific database
        db_name = sys.argv[1]
        num_queries = int(sys.argv[2]) if len(sys.argv) > 2 else 10
        test_specific_database(db_name, num_queries)
    else:
        # Run batch test
        executor = QueryExecutor()
        results = executor.execute_batch_test(num_databases=3, queries_per_db=5)
        
        if results:
            executor.save_results(results)
            executor.analyze_errors(results) 